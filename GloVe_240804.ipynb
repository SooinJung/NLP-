{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SooinJung/NLP-/blob/main/GloVe_240804.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG95ggNhiJa6",
        "outputId": "fa2aedbe-20d8-40be-d125-ca9a153d749b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\r0% [Waiting for headers] [Connected to cloud.r-project.org (52.85.151.8)] [Connecting to r2u.stat.il\r                                                                                                    \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to r2u.stat.illinois.edu (192.17.190.167)]\r                                                                                                    \rHit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Waiting for headers] [Connected to r2u.stat.illinois.edu (192.17.190.167)] [Waiting for headers]\r                                                                                                    \rHit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "\r0% [Waiting for headers] [Connected to r2u.stat.illinois.edu (192.17.190.167)] [Waiting for headers]\r                                                                                                    \rHit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "\r0% [Connected to r2u.stat.illinois.edu (192.17.190.167)] [Waiting for headers] [Connected to ppa.lau\r                                                                                                    \rHit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Connected to r2u.stat.illinois.edu (192.17.190.167)] [Connected to ppa.launchpadcontent.net (185\r                                                                                                    \r0% [Waiting for headers] [Connected to ppa.launchpadcontent.net (185.125.190.80)]\r                                                                                 \rIgn:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://r2u.stat.illinois.edu/ubuntu jammy Release\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "python3-dev is already the newest version (3.10.6-1~22.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 48 not upgraded.\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (72.1.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement glove-python-binary (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for glove-python-binary\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install -y build-essential python3-dev\n",
        "!pip install -U pip setuptools\n",
        "!pip install glove-python-binary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install glove-python3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySpw0nI0COMo",
        "outputId": "8e6d02cc-7ec9-454c-9cba-6fc780fd91b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting glove-python3\n",
            "  Downloading glove_python3-0.1.0.tar.gz (326 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.0/327.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from glove-python3) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from glove-python3) (1.13.1)\n",
            "Building wheels for collected packages: glove-python3\n",
            "  Building wheel for glove-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for glove-python3: filename=glove_python3-0.1.0-cp310-cp310-linux_x86_64.whl size=1065521 sha256=662a5c1817ee487702edd5b67df20197f9061a8ffc2ad68d160d42be61deabd1\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/2f/79/34314d44a0907e90e323c8c182ec23f126eb460829e02d98cf\n",
            "Successfully built glove-python3\n",
            "Installing collected packages: glove-python3\n",
            "Successfully installed glove-python3-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위에 glove-python-binary가 다운이 안받아져서 다른 실습으로 진행하고자 한다.\n",
        "\n",
        "https://janghan-kor.tistory.com/603\n",
        "\n",
        "미리 학습된 GloVe 벡터를 로드한다. <br>\n",
        "- name 필드: 벡터가 학습된 데이터를 지정\n",
        "- 6B : 60억 개의 단어 코퍼스\n",
        "- dim 인수: 단어 벡터 차원 지정\n",
        "  - GloVe 벡터 : 50, 100, 200 및 300 차원으로 제공된다.\n"
      ],
      "metadata": {
        "id": "fZBXC2Q8kpDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext.vocab\n",
        "\n",
        "glove = torchtext.vocab.GloVe(name='6B', dim=100) # 이미 학습된 것을 불러오기만 하는 것임. torchtext의 vocab에 존재.\n",
        "# hidden size를 몇으로 정할래이다. V -> hidden (100 / 300 / 512 / 256)\n",
        "print(f'There are {len(glove.itos)} words in the vocabulary')\n",
        "# itos -> dictionary의 사이즈가 무엇이냐는 것.\n",
        "# 우리는 지금 아래와 같이 400000개의 words를 사용 가능함."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D_2ExdwiVcg",
        "outputId": "5fce69ed-64ca-45be-8f42-68c44bb01032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            ".vector_cache/glove.6B.zip: 862MB [02:41, 5.32MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:27<00:00, 14694.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 400000 words in the vocabulary\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove.vectors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dALrbPCRkmCj",
        "outputId": "7e8e5aea-08db-40cc-8bcd-aefc43004f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([400000, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 사전 크기 출력\n",
        "print(f'There are {len(glove.itos)} words in the vocabulary')\n",
        "\n",
        "# 사전의 첫 5개 단어와 해당 벡터를 출력\n",
        "for i in range(5):\n",
        "    word = glove.itos[i]\n",
        "    vector = glove.vectors[i]\n",
        "    print(f'Word: {word}, Vector: {vector[:5]}...')  # 벡터의 앞부분만 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4v0r1JKqlOvp",
        "outputId": "375b546b-b1fe-41ad-abd5-962db8ba4db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 400000 words in the vocabulary\n",
            "Word: the, Vector: tensor([-0.0382, -0.2449,  0.7281, -0.3996,  0.0832])...\n",
            "Word: ,, Vector: tensor([-0.1077,  0.1105,  0.5981, -0.5436,  0.6740])...\n",
            "Word: ., Vector: tensor([-0.3398,  0.2094,  0.4635, -0.6479, -0.3838])...\n",
            "Word: of, Vector: tensor([-0.1529, -0.2428,  0.8984,  0.1700,  0.5352])...\n",
            "Word: to, Vector: tensor([-0.1897,  0.0500,  0.1908, -0.0492, -0.0897])...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove.itos[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7VE2YPqloDn",
        "outputId": "c44b40d5-4b6e-41ff-eebb-8263200f0ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " ',',\n",
              " '.',\n",
              " 'of',\n",
              " 'to',\n",
              " 'and',\n",
              " 'in',\n",
              " 'a',\n",
              " '\"',\n",
              " \"'s\",\n",
              " 'for',\n",
              " '-',\n",
              " 'that',\n",
              " 'on',\n",
              " 'is',\n",
              " 'was',\n",
              " 'said',\n",
              " 'with',\n",
              " 'he',\n",
              " 'as',\n",
              " 'it',\n",
              " 'by',\n",
              " 'at',\n",
              " '(',\n",
              " ')',\n",
              " 'from',\n",
              " 'his',\n",
              " \"''\",\n",
              " '``',\n",
              " 'an',\n",
              " 'be',\n",
              " 'has',\n",
              " 'are',\n",
              " 'have',\n",
              " 'but',\n",
              " 'were',\n",
              " 'not',\n",
              " 'this',\n",
              " 'who',\n",
              " 'they',\n",
              " 'had',\n",
              " 'i',\n",
              " 'which',\n",
              " 'will',\n",
              " 'their',\n",
              " ':',\n",
              " 'or',\n",
              " 'its',\n",
              " 'one',\n",
              " 'after',\n",
              " 'new',\n",
              " 'been',\n",
              " 'also',\n",
              " 'we',\n",
              " 'would',\n",
              " 'two',\n",
              " 'more',\n",
              " \"'\",\n",
              " 'first',\n",
              " 'about',\n",
              " 'up',\n",
              " 'when',\n",
              " 'year',\n",
              " 'there',\n",
              " 'all',\n",
              " '--',\n",
              " 'out',\n",
              " 'she',\n",
              " 'other',\n",
              " 'people',\n",
              " \"n't\",\n",
              " 'her',\n",
              " 'percent',\n",
              " 'than',\n",
              " 'over',\n",
              " 'into',\n",
              " 'last',\n",
              " 'some',\n",
              " 'government',\n",
              " 'time',\n",
              " '$',\n",
              " 'you',\n",
              " 'years',\n",
              " 'if',\n",
              " 'no',\n",
              " 'world',\n",
              " 'can',\n",
              " 'three',\n",
              " 'do',\n",
              " ';',\n",
              " 'president',\n",
              " 'only',\n",
              " 'state',\n",
              " 'million',\n",
              " 'could',\n",
              " 'us',\n",
              " 'most',\n",
              " '_',\n",
              " 'against',\n",
              " 'u.s.']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove.stoi['the'] # 단어가 몇 번째에 존재하냐. keyerror 는 없는 것.\n",
        "# 가장 많이 등장하는 단어를 앞에서부터 넣는다.\n",
        "print(glove.stoi['the'])\n",
        "glove.vectors[glove.stoi['the']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8naq9zUlrU5",
        "outputId": "5c009878-8a5d-4f8d-a098-14d632da755e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0382, -0.2449,  0.7281, -0.3996,  0.0832,  0.0440, -0.3914,  0.3344,\n",
              "        -0.5755,  0.0875,  0.2879, -0.0673,  0.3091, -0.2638, -0.1323, -0.2076,\n",
              "         0.3340, -0.3385, -0.3174, -0.4834,  0.1464, -0.3730,  0.3458,  0.0520,\n",
              "         0.4495, -0.4697,  0.0263, -0.5415, -0.1552, -0.1411, -0.0397,  0.2828,\n",
              "         0.1439,  0.2346, -0.3102,  0.0862,  0.2040,  0.5262,  0.1716, -0.0824,\n",
              "        -0.7179, -0.4153,  0.2033, -0.1276,  0.4137,  0.5519,  0.5791, -0.3348,\n",
              "        -0.3656, -0.5486, -0.0629,  0.2658,  0.3020,  0.9977, -0.8048, -3.0243,\n",
              "         0.0125, -0.3694,  2.2167,  0.7220, -0.2498,  0.9214,  0.0345,  0.4674,\n",
              "         1.1079, -0.1936, -0.0746,  0.2335, -0.0521, -0.2204,  0.0572, -0.1581,\n",
              "        -0.3080, -0.4162,  0.3797,  0.1501, -0.5321, -0.2055, -1.2526,  0.0716,\n",
              "         0.7056,  0.4974, -0.4206,  0.2615, -1.5380, -0.3022, -0.0734, -0.2831,\n",
              "         0.3710, -0.2522,  0.0162, -0.0171, -0.3898,  0.8742, -0.7257, -0.5106,\n",
              "        -0.5203, -0.1459,  0.8278,  0.2706])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "우리의 목적은 단어의 인덱스에서 Vector를 가지고 오는 것이다!\n",
        "\n",
        "해당 벡터는 400000 * 100 차원\n",
        "\n",
        "the 라는 단어 가져오려면 -> the 라는 단어 인덱스를 0으로 부여."
      ],
      "metadata": {
        "id": "ySJCO6gRl2kR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#임베딩에 벡터의 값을 넣고 입데잉에 대한 단어를 알려주는 함수\n",
        "def get_vector(embeddings, word):\n",
        "  return embeddings.vectors[embeddings.stoi[word]]"
      ],
      "metadata": {
        "id": "hpeVkVsjl14M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "#가장 가까운 것을 찾아서 n개 리턴해주는 함수\n",
        "def closest_words(embeddings, vector, n=10):\n",
        "    distances = [(w, torch.dist(vector, get_vector(embeddings, w)).item()) for w in embeddings.itos]\n",
        "    return sorted(distances, key = lambda w: w[1])[:n]"
      ],
      "metadata": {
        "id": "psIJbzV-mRnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "closest_words(glove, get_vector(glove, 'korea'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiTG8E6Dmeih",
        "outputId": "1951dbf3-130b-4e27-991d-78c231ba4e3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('korea', 0.0),\n",
              " ('pyongyang', 3.9039547443389893),\n",
              " ('korean', 4.068886756896973),\n",
              " ('dprk', 4.2631049156188965),\n",
              " ('seoul', 4.340494632720947),\n",
              " ('japan', 4.551243305206299),\n",
              " ('koreans', 4.615607738494873),\n",
              " ('south', 4.65822696685791),\n",
              " ('china', 4.8395185470581055),\n",
              " ('north', 4.986356735229492)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# distance와 단어가 깔끔하게 출력되도록 해주는 함수\n",
        "def print_tuples(tuples):\n",
        "    for w, d in tuples:\n",
        "        print(f'({d:02.04f}) {w}')"
      ],
      "metadata": {
        "id": "WlQ_ZFQQmiYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_tuples(closest_words(glove, get_vector(glove, 'ai')))\n",
        "# embedding 학습한 데이터가 general 하다는 점, 대화 형식의 데이터를 학습했기 때문에 현재 관련 없는 것들이 나온다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lArSgJGmliP",
        "outputId": "33f0f9e9-b8eb-4549-8801-58e08028b307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.0000) ai\n",
            "(4.5332) hey\n",
            "(4.5842) ok\n",
            "(4.6785) fukuhara\n",
            "(4.8145) fortunately\n",
            "(4.8299) 'cause\n",
            "(4.8935) yeah\n",
            "(4.9061) hi\n",
            "(4.9083) luckily\n",
            "(4.9333) …\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#벡터들을 빼고 더하기를 하는 함수\n",
        "def analogy(embeddings, word1, word2, word3, n=5):\n",
        "\n",
        "    candidate_words = closest_words(embeddings, get_vector(embeddings, word2) - get_vector(embeddings, word1) + get_vector(embeddings, word3), n+3)\n",
        "\n",
        "    candidate_words = [x for x in candidate_words if x[0] not in [word1, word2, word3]][:n]\n",
        "\n",
        "    print(f'{word1} is to {word2} as {word3} is to...')\n",
        "\n",
        "    return candidate_words"
      ],
      "metadata": {
        "id": "yQWDAixTnBm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_tuples(analogy(glove, 'summer', 'hot', 'winter', n = 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4Ug3X66nMlG",
        "outputId": "bc37257b-8710-40a7-9c4f-2681c97442af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summer is to hot as winter is to...\n",
            "(4.2799) cold\n",
            "(4.7726) cool\n",
            "(4.8650) warm\n",
            "(4.9227) dry\n",
            "(5.0521) wet\n",
            "(5.1538) snow\n",
            "(5.1732) soft\n",
            "(5.2819) cooler\n",
            "(5.2956) chill\n",
            "(5.3611) heat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_tuples(analogy(glove, 'man', 'king', 'woman', n = 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTcwxMCQncLZ",
        "outputId": "b04d8dab-3ae1-4c02-9c3b-64b75f47278d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "man is to king as woman is to...\n",
            "(4.0811) queen\n",
            "(4.6429) monarch\n",
            "(4.9055) throne\n",
            "(4.9216) elizabeth\n",
            "(4.9811) prince\n",
            "(4.9857) daughter\n",
            "(5.0641) mother\n",
            "(5.0775) cousin\n",
            "(5.0787) princess\n",
            "(5.1283) widow\n"
          ]
        }
      ]
    }
  ]
}